# Module 1: Introduction to Deep Learning

This module provides a foundational overview of deep learning, including how it differs from traditional machine learning and why it has become essential in fields like computer vision, natural language processing, and biomedical AI.

## Topics Covered

- What is deep learning?
- Key differences between deep learning and classical machine learning
- Why deep learning now? (hardware, data, algorithms)
- Structure and intuition behind neural networks
- Use cases across industries

## Notebook(s)

- `intro_to_dl.ipynb` – Covers theory and practical examples illustrating the advantages of deep learning.

## Learning Objectives

- Understand the core motivations for deep learning
- Recognize major application domains
- Describe the basic architecture of a neural network
- Identify factors contributing to the growth of deep learning

## Resources

- [Course link](https://www.coursera.org/learn/introduction-to-deep-learning-with-keras)
- Optional reading: [Deep Learning Specialization by Andrew Ng](https://www.coursera.org/specializations/deep-learning)

## Did you Know? 
* Deep learning is one of the hottest subjects in data science. 
* Color restoration applications can automatically convert a grayscale image into a colored image. 
* Speech enactment applications can synthesize audio clips with lip movements in videos, extracting audio from one video and syncing its lip movements with the audio from another video. 
* Handwriting generation applications can rewrite a provided message in highly realistic cursive handwriting in a wide variety of styles. 
* Deep learning algorithms are largely inspired by the way neurons and neural networks function and process data in the brain. 
* The main body of a neuron is the soma, and the extensive network of arms that stick out of the body are called dendrites. The long arm that sticks out of the soma in the other direction is called the axon.  
* Whiskers at the end of the axon are called the synapses.  
* Dendrites receive electrical impulses that carry information from synapses of other adjoining neurons. Dendrites carry the impulses to the soma.  
* In the nucleus, electrical impulses are processed by combining them, and then they are passed on to the axon. The axon carries the processed information to the synapses, and the output of this neuron becomes the input to thousands of other neurons. 
* Learning in the brain occurs by repeatedly activating certain neural connections over others, and this reinforces those connections. 
* An artificial neuron behaves in the same way as a biological neuron. 
* The first layer that feeds input into the neural network is the input layer. 
* The set of nodes that provide network output is the output layer. 
* Any sets of nodes in between the input and output layers are the hidden layers. 
* Forward propagation is the process through which data passes through layers of neurons in a neural network from the input layer to the output layer.
* Given a neural network with weights and biases, you can compute the network output for any given input. 