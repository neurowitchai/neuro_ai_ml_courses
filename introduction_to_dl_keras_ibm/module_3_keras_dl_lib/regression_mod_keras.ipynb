{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a83720-5ba3-4ce8-8eab-5a8df76ec539",
   "metadata": {},
   "source": [
    "# Regression Models with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b64c14-dc37-492f-91fe-2368081cc01d",
   "metadata": {},
   "source": [
    "## Objectives for this Notebook\n",
    "* How to use the Keras library to build a regression model\n",
    "* Download and clean the data set\n",
    "* Build a neural network\n",
    "* Train and test the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4954c7-1900-4a7a-90dd-d6545fbcc763",
   "metadata": {},
   "source": [
    "## Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefb3cbc-8db8-47eb-962b-24d892955f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==2.0.2\n",
    "!pip install pandas==2.2.2\n",
    "!pip install tensorflow_cpu==2.18.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1073e-b390-4cad-8c8e-95f6b25cb747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c52eb-f7d0-4659-9817-1aae7a820e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3500f67c-73a5-4bda-8278-5d1289a15e19",
   "metadata": {},
   "source": [
    "## Download and Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124fee44-5310-474f-aa9f-c5b37f28c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath='https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv'\n",
    "concrete_data = pd.read_csv(filepath)\n",
    "\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0ff28a-a216-4931-9fbd-153b7f708636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check num of data points\n",
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b869a-f529-4c8a-86a2-d4a8a15a79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataset for missing values\n",
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff5af6-cac5-4f83-bccb-e1d474336912",
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded9bbd-06a9-4195-b4a1-42be4be436d5",
   "metadata": {},
   "source": [
    "## Split data into predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97affb5d-b0ca-474a-87ca-594897691872",
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579667e8-a619-4906-a9dd-a539be20d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18cf47-f132-4025-90b9-706fc1da3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(predictors.head())\n",
    "print(target.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6672e78b-b245-4ee3-a89e-e54590e283fe",
   "metadata": {},
   "source": [
    "## Normalize data\n",
    "Finally, the last step is to normalize the data by substracting the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96019290-3240-4b2b-bb96-389b0da1c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc8461-ebaf-4808-85b7-a1e826736473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the number of predictors to n_cols since we will need this number when building our network.\n",
    "n_cols = predictors_norm.shape[1] # number of predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13212e0e-862c-4c98-b690-9efdd4357346",
   "metadata": {},
   "source": [
    "## Import Keras Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21744a-e382-4ed1-b3e6-b12a22bd2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to build regression model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342ea10a-870b-4fca-9d6a-d098bde61180",
   "metadata": {},
   "source": [
    "## Build a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a312cb8e-74af-4a60-bbb3-77e6db414619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define regression model\n",
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(n_cols,)))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736f230-7ea1-401e-b57d-e347b6a8bf26",
   "metadata": {},
   "source": [
    "## Train and Test network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041de0e8-e06f-459e-9b08-3cc32d43fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "model = regression_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38c3ee-363d-4796-b359-e38c286d11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will train and test the model at the same time using the fit method. \n",
    "#   We will leave out 30% of the data for validation and we will train the model \n",
    "#   for 100 epochs.\n",
    "# fit the model\n",
    "model.fit(predictors_norm, target, validation_split=0.3, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60246f-46ef-4d93-871f-7af349aa0b3b",
   "metadata": {},
   "source": [
    "* Adding more hidden layers to the model increases its capacity to learn and represent complex relationships within the data. This allows the model to better identify, as a result, the model becomes more effective at fitting the training data and potentially improving its predictions.\n",
    "* By reducing the proportion of data set aside for validation and using a larger portion for training, the model has access to more examples to learn from. This additional training data helps the model improve its understanding of the underlying trends, which can lead to better overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77922a4c-64e6-4a8e-be13-e9f0614f9f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
