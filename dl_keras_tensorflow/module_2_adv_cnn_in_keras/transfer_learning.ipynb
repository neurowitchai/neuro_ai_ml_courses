{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b982f678-6e90-43d7-91ee-20a6088242af",
   "metadata": {},
   "source": [
    "# Transfer learning implementation\n",
    "\n",
    "#### Learning objectives\n",
    "\n",
    "By the end of this lab, you will:\n",
    "\n",
    " - Import necessary libraries and load the dataset.\n",
    " - Load a pre-trained model, VGG16, excluding the top layers.\n",
    " - Add new layers on top of the base model and compile the model.\n",
    " - Train the model on the new dataset.\n",
    " - Unfreeze some of the layers of the pre-trained model and fine-tune them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd67b4-f92c-4776-9939-89b908b5eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.16.2 matplotlib==3.9.1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d9013-caa3-446e-85d7-af2fabebf7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 model pre-trained on ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5982d79-5e43-4e6f-a623-833251c63298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model and add the base model and new layers\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Change to the number of classes you have\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ecac54-1f39-4f8c-98f4-26e70ca3f0cf",
   "metadata": {},
   "source": [
    "#### Create placeholder images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ba0dd-2a09-4b92-a0d3-7d376d4eb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('sample_data/class_a', exist_ok=True)\n",
    "os.makedirs('sample_data/class_b', exist_ok=True)\n",
    "\n",
    "# Create 10 sample images for each class\n",
    "for i in range(10):\n",
    "    # Create a blank white image for class_a\n",
    "    img = Image.fromarray(np.ones((224, 224, 3), dtype=np.uint8) * 255)\n",
    "    img.save(f'sample_data/class_a/img_{i}.jpg')\n",
    "\n",
    "    # Create a blank black image for class_b\n",
    "    img = Image.fromarray(np.zeros((224, 224, 3), dtype=np.uint8))\n",
    "    img.save(f'sample_data/class_b/img_{i}.jpg')\n",
    "\n",
    "print(\"Sample images created in 'sample_data/'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9827d2d7-3203-439e-b4be-b0d59060d7b1",
   "metadata": {},
   "source": [
    "#### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb2975-2070-4230-a1f8-890660a1c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'sample_data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Verify if the generator has loaded images correctly\n",
    "print(f\"Found {train_generator.samples} images belonging to {train_generator.num_classes} classes.\")\n",
    "\n",
    "# Train the model\n",
    "if train_generator.samples > 0:\n",
    "    model.fit(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fabb1d-6e8a-451a-bf21-2502ae142267",
   "metadata": {},
   "source": [
    "#### fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9347e7-cb61-41c9-9be5-110e08d5b5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the top layers of the base model \n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# compile model again\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train model again\n",
    "model.fit(train_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386b493-33c6-4fd9-9e48-189d92eada43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
